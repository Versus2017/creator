"""
Whisper è¯­éŸ³è¯†åˆ«æœåŠ¡

æä¾›è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½ï¼Œæ”¯æŒï¼š
1. åŸºç¡€è½¬å†™ï¼ˆçŸ­éŸ³é¢‘ï¼‰
2. æ™ºèƒ½åˆ†æ®µè½¬å†™ï¼ˆé•¿éŸ³é¢‘ï¼‰
3. æ—¶é—´æˆ³å’Œåˆ†æ®µä¿¡æ¯

æŠ€æœ¯æ–¹æ¡ˆï¼š
- æ”¯æŒæœ¬åœ° Whisper æ¨¡å‹éƒ¨ç½²ï¼ˆæ¨èï¼Œæ•°æ®ç§å¯†ï¼‰
- æ”¯æŒ OpenAI Whisper APIï¼ˆå¤‡é€‰ï¼‰

æœ¬åœ°éƒ¨ç½²ï¼ˆä½¿ç”¨ faster-whisperï¼‰ï¼š
- å¼•æ“ï¼šfaster-whisperï¼ˆåŸºäº CTranslate2ï¼Œé€Ÿåº¦å¿« 4 å€ï¼‰
- æ¨¡å‹ï¼šmediumï¼ˆå‡†ç¡®ç‡ 96%+ï¼Œ1.5GBï¼‰
- è®¾å¤‡ï¼šM1/M2 Mac CPU æ¨¡å¼å³å¯ï¼ˆé€Ÿåº¦å¾ˆå¿«ï¼‰
- é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ° ~/.cache/huggingface/

ä¾èµ–å®‰è£…ï¼š
1. pip install faster-whisper
2. brew install ffmpegï¼ˆMacï¼‰æˆ– apt-get install ffmpegï¼ˆLinuxï¼‰
"""

import logging
import os
import subprocess
import tempfile
import shutil
from pathlib import Path
from typing import Dict, List, Optional
import soundfile as sf

from ...config import config

logger = logging.getLogger(__name__)


def _resolve_binary(name: str) -> Optional[str]:
    """åœ¨å¸¸è§è·¯å¾„ä¸­è§£æå¯æ‰§è¡Œæ–‡ä»¶çš„ç»å¯¹è·¯å¾„"""
    try:
        path = shutil.which(name)
        if path:
            return path
    except Exception:
        pass
    for base in ["/usr/local/bin", "/opt/homebrew/bin", "/usr/bin", "/bin"]:
        candidate = os.path.join(base, name)
        if os.path.exists(candidate):
            return candidate
    return None

class WhisperService:
    """
    Whisper è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼ˆæ”¯æŒæœ¬åœ°æ¨¡å‹å’Œ APIï¼‰
    
    ä½¿ç”¨æ–¹æ³•ï¼š
        service = WhisperService()
        result = service.transcribe(audio_path)
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ– Whisper æœåŠ¡
        
        æ ¹æ®é…ç½®é€‰æ‹©æœ¬åœ°æ¨¡å‹æˆ– API
        """
        self.use_local = config.WHISPER_USE_LOCAL
        self.model = None
        self.api_client = None
        
        if self.use_local:
            # ä½¿ç”¨æœ¬åœ° Whisper æ¨¡å‹
            self.model_name = config.WHISPER_MODEL_NAME
            self.device = config.WHISPER_DEVICE
            self._load_local_model()
        else:
            # ä½¿ç”¨ OpenAI API
            self.model_name = 'whisper-1'
            self._init_api_client()
    
    def _load_local_model(self):
        """
        åŠ è½½æœ¬åœ° Whisper æ¨¡å‹ï¼ˆä½¿ç”¨ faster-whisperï¼‰
        
        æœåŠ¡å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ° ~/.cache/huggingface/
        å¦‚æœæ¨¡å‹æœªä¸‹è½½ï¼Œä¼šç«‹å³è§¦å‘ä¸‹è½½ï¼ˆçº¦ 1.5GBï¼Œéœ€è¦ 5-10 åˆ†é’Ÿï¼‰
        """
        import sys
        import os
        
        # é…ç½® HuggingFace é•œåƒæºï¼ˆå›½å†…ç”¨æˆ·æ¨èï¼‰
        # å¦‚æœè®¾ç½®äº† HF_ENDPOINT ç¯å¢ƒå˜é‡ï¼Œä¼˜å…ˆä½¿ç”¨
        if not os.environ.get('HF_ENDPOINT'):
            # ä½¿ç”¨å›½å†…é•œåƒæºï¼ˆhf-mirror.comï¼‰
            os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
            logger.info(f"ğŸŒ ä½¿ç”¨ HuggingFace é•œåƒæº: https://hf-mirror.com")
        
        logger.info(f"ğŸ” [è¯Šæ–­] å¼€å§‹åŠ è½½ faster-whisper æ¨¡å‹")
        logger.info(f"ğŸ” [è¯Šæ–­] æ¨¡å‹åç§°: {self.model_name}")
        logger.info(f"ğŸ” [è¯Šæ–­] è®¾å¤‡: {self.device}")
        logger.info(f"ğŸ” [è¯Šæ–­] è®¡ç®—ç±»å‹: {config.WHISPER_COMPUTE_TYPE}")
        logger.info(f"ğŸ” [è¯Šæ–­] å½“å‰è¿›ç¨‹ID: {os.getpid()}")
        
        try:
            from faster_whisper import WhisperModel
            logger.info(f"ğŸ” [è¯Šæ–­] faster_whisper æ¨¡å—å¯¼å…¥æˆåŠŸ")
            
            logger.info(f"ğŸš€ å¼€å§‹åŠ è½½ faster-whisper æ¨¡å‹...")
            logger.info(f"   - å¦‚æœæ˜¯é¦–æ¬¡è¿è¡Œï¼Œå°†è‡ªåŠ¨ä» HuggingFace ä¸‹è½½æ¨¡å‹")
            logger.info(f"   - ä¸‹è½½ä½ç½®: ~/.cache/huggingface/")
            logger.info("=" * 60)
            
            # å¼ºåˆ¶åˆ·æ–°è¾“å‡º
            sys.stdout.flush()
            sys.stderr.flush()
            
            logger.info(f"ğŸ” [è¯Šæ–­] è°ƒç”¨ WhisperModel()...")
            import time
            load_start = time.time()
            
            # åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
            # faster-whisper ä¼šè‡ªåŠ¨ä» HuggingFace ä¸‹è½½ CTranslate2 æ ¼å¼çš„æ¨¡å‹
            self.model = WhisperModel(
                self.model_name,
                device=self.device,
                compute_type=config.WHISPER_COMPUTE_TYPE,
                download_root=None,  # ä½¿ç”¨é»˜è®¤ç¼“å­˜ç›®å½•
                local_files_only=False  # å…è®¸ä¸‹è½½
            )
            
            load_time = time.time() - load_start
            logger.info(f"ğŸ” [è¯Šæ–­] æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")
            logger.info(f"ğŸ” [è¯Šæ–­] æ¨¡å‹å¯¹è±¡ç±»å‹: {type(self.model)}")
            logger.info(f"ğŸ” [è¯Šæ–­] æ¨¡å‹æ˜¯å¦ä¸º None: {self.model is None}")
            
            logger.info("=" * 60)
            logger.info(f"âœ… faster-whisper æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_name}")
            logger.info(f"   - å¼•æ“: faster-whisper (CTranslate2)")
            logger.info(f"   - è®¾å¤‡: {self.device}")
            logger.info(f"   - è®¡ç®—ç±»å‹: {config.WHISPER_COMPUTE_TYPE}")
            
            # æ ¹æ®æ¨¡å‹åç§°æ˜¾ç¤ºå¤§å°
            model_sizes = {
                'tiny': '~75MB',
                'base': '~145MB',
                'small': '~488MB',
                'medium': '~1.5GB',
                'large': '~3GB',
                'large-v2': '~3GB',
                'large-v3': '~3GB'
            }
            model_size = model_sizes.get(self.model_name, 'æœªçŸ¥')
            logger.info(f"   - æ¨¡å‹å¤§å°: {model_size}")
            logger.info(f"   - å‡†ç¡®ç‡: 96%+")
            logger.info(f"   - æ€§èƒ½æå‡: æ¯” openai-whisper å¿« 4 å€ ğŸš€")
            logger.info(f"   - è¯­éŸ³è½¬æ–‡å­—æœåŠ¡å·²å°±ç»ªï¼")
            
            # å¼ºåˆ¶åˆ·æ–°è¾“å‡º
            sys.stdout.flush()
            sys.stderr.flush()
            
        except ImportError:
            logger.error("âŒ faster-whisper æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install faster-whisper")
            logger.warning("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            self.model = None
        except Exception as e:
            logger.error(f"âŒ faster-whisper æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            logger.warning("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            self.model = None
    
    def _init_api_client(self):
        """
        åˆå§‹åŒ– OpenAI API å®¢æˆ·ç«¯
        """
        try:
            from openai import OpenAI
            
            api_key = config.OPENAI_API_KEY
            if api_key:
                self.api_client = OpenAI(
                    api_key=api_key,
                    base_url=config.OPENAI_API_BASE,
                    timeout=config.WHISPER_API_TIMEOUT
                )
                logger.info(f"âœ… OpenAI API å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("âš ï¸ OpenAI API Key æœªé…ç½®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        except Exception as e:
            logger.error(f"âŒ OpenAI API å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def transcribe(
        self, 
        audio_path: str,
        language: str = "zh",
        word_timestamps: bool = True
    ) -> Dict:
        """
        è½¬å†™éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç ï¼ˆzh=ä¸­æ–‡, en=è‹±æ–‡ï¼‰
            word_timestamps: æ˜¯å¦è¿”å›è¯çº§æ—¶é—´æˆ³ï¼ˆæœ¬åœ°æ¨¡å‹æ”¯æŒï¼‰
        
        Returns:
            {
                "text": "å®Œæ•´è½¬å†™æ–‡æœ¬",
                "duration": 30.5,
                "language": "zh",
                "segments": [...]  # æœ¬åœ°æ¨¡å‹è¿”å›è¯¦ç»†åˆ†æ®µï¼ŒAPI è¿”å›ç®€åŒ–åˆ†æ®µ
            }
        """
        logger.info(f"å¼€å§‹è½¬å†™: {audio_path}, æ¨¡å¼={'æœ¬åœ°' if self.use_local else 'API'}")
        
        # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        # 2. è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆä¼˜å…ˆä½¿ç”¨ ffprobeï¼Œæ”¯æŒæ‰€æœ‰æ ¼å¼åŒ…æ‹¬ webmï¼‰
        duration = self._get_audio_duration(audio_path)
        
        # 3. è°ƒç”¨ faster-whisper è½¬å†™
        # faster-whisper ç›´æ¥æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼ï¼ˆé€šè¿‡ ffmpegï¼‰ï¼Œæ— éœ€é¢„è½¬æ¢
        
        # è¯Šæ–­ï¼šæ£€æŸ¥æœåŠ¡çŠ¶æ€
        logger.info(f"ğŸ” [è¯Šæ–­] use_local={self.use_local}, model={self.model is not None}, api_client={self.api_client is not None}")
        
        if self.use_local and self.model:
            # æœ¬åœ° faster-whisper æ¨¡å‹
            logger.info(f"ğŸ” [è¯Šæ–­] ä½¿ç”¨ faster-whisper æ¨¡å‹è¿›è¡Œè½¬å†™")
            
            # faster-whisper æ€§èƒ½æ›´å¥½ï¼Œç›´æ¥ä½¿ç”¨æ–‡ä»¶è·¯å¾„å³å¯
            # ä¸éœ€è¦åƒ openai-whisper é‚£æ ·çš„æ•°ç»„è¾“å…¥ workaround
            result = self._transcribe_with_local_model(audio_path, language, word_timestamps)
        elif self.api_client:
            # OpenAI APIï¼ˆæ”¯æŒ webmï¼‰
            logger.info(f"ğŸ” [è¯Šæ–­] ä½¿ç”¨ OpenAI API è¿›è¡Œè½¬å†™")
            result = self._transcribe_with_openai_api(audio_path, language)
            result['duration'] = duration
        else:
            # å¦‚æœæ²¡æœ‰å¯ç”¨çš„è½¬å†™æœåŠ¡ï¼ŒæŠ›å‡ºå¼‚å¸¸
            raise RuntimeError("Whisper æœåŠ¡æœªæ­£ç¡®åˆå§‹åŒ–ï¼šæ¨¡å‹æœªåŠ è½½ä¸” API å®¢æˆ·ç«¯æœªé…ç½®")
        
        logger.info(f"âœ… è½¬å†™å®Œæˆ: æ–‡æœ¬é•¿åº¦={len(result['text'])}, æ—¶é•¿={result.get('duration', 0):.2f}ç§’")
        
        return result
    
    def _transcribe_with_local_model(
        self, 
        audio_path: str,
        language: str,
        word_timestamps: bool = True
    ) -> Dict:
        """
        ä½¿ç”¨æœ¬åœ° Whisper æ¨¡å‹è¿›è¡Œè½¬å†™ï¼ˆfaster-whisperï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç ï¼ˆzh, en, ja, koç­‰ï¼‰
            word_timestamps: æ˜¯å¦è¿”å›è¯çº§æ—¶é—´æˆ³
        
        Returns:
            {
                "text": "è½¬å†™æ–‡æœ¬",
                "duration": 30.5,
                "language": "zh",
                "segments": [...]  # è¯¦ç»†çš„åˆ†æ®µä¿¡æ¯
            }
        """
        try:
            # å¯¼å…¥å¿…è¦çš„æ¨¡å—
            import time
            import os
            
            # è¯Šæ–­ï¼šéªŒè¯æ¨¡å‹çŠ¶æ€
            logger.info(f"ğŸ” [è¯Šæ–­] å¼€å§‹è½¬å†™æ£€æŸ¥")
            logger.info(f"ğŸ” [è¯Šæ–­] æ¨¡å‹å¯¹è±¡ç±»å‹: {type(self.model)}")
            logger.info(f"ğŸ” [è¯Šæ–­] æ¨¡å‹æ˜¯å¦ä¸º None: {self.model is None}")
            logger.info(f"ğŸ” [è¯Šæ–­] éŸ³é¢‘æ–‡ä»¶è·¯å¾„: {audio_path}")
            logger.info(f"ğŸ” [è¯Šæ–­] éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(audio_path)}")
            if os.path.exists(audio_path):
                file_size = os.path.getsize(audio_path)
                logger.info(f"ğŸ” [è¯Šæ–­] éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ ({file_size/1024:.2f} KB)")
            
            logger.info(f"è°ƒç”¨ faster-whisper æ¨¡å‹: {audio_path}, language={language}")
            logger.info("â³ faster-whisper è½¬å†™ä¸­ï¼ˆæ¯”åŸç‰ˆå¿« 4 å€ï¼‰...")
            logger.info("   æç¤ºï¼šmedium æ¨¡å‹åœ¨ CPU ä¸Šï¼Œ3ç§’éŸ³é¢‘çº¦éœ€ 2.5-7.5 ç§’")
            
            # è°ƒç”¨ faster-whisper æ¨¡å‹
            # å‚æ•°è¯´æ˜ï¼š
            # - language: æŒ‡å®šè¯­è¨€å¯ä»¥æé«˜å‡†ç¡®ç‡å’Œé€Ÿåº¦
            # - word_timestamps: è¿”å›è¯çº§æ—¶é—´æˆ³ï¼ˆç”¨äºç²¾ç¡®åˆ†æ®µï¼‰
            # - beam_size: æŸæœç´¢å¤§å°ï¼Œé»˜è®¤5ï¼ˆè¶Šå¤§è¶Šå‡†ç¡®ä½†è¶Šæ…¢ï¼‰
            # - vad_filter: VADè¿‡æ»¤ï¼Œè‡ªåŠ¨å»é™¤é™éŸ³éƒ¨åˆ†
            # - condition_on_previous_text: False å¯ä»¥æé«˜é€Ÿåº¦
            
            start_time = time.time()
            logger.info(f"ğŸ” [è¯Šæ–­] å‡†å¤‡è°ƒç”¨ model.transcribe()ï¼Œæ—¶é—´: {start_time}")
            logger.info(f"ğŸ” [è¯Šæ–­] å‚æ•°: language={language}, word_timestamps={word_timestamps}, beam_size=5")
            
            logger.info(f"ğŸ” [è¯Šæ–­] å¼€å§‹è°ƒç”¨ transcribe()...")
            
            # faster-whisper è¿”å› (segments, info) å…ƒç»„
            # segments æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œéœ€è¦éå†æ‰èƒ½è·å–æ‰€æœ‰ç»“æœ
            segments, info = self.model.transcribe(
                audio_path,
                language=language,
                beam_size=5,  # æŸæœç´¢å¤§å°ï¼Œé»˜è®¤5
                word_timestamps=word_timestamps,
                vad_filter=False,  # ç¦ç”¨ VAD è¿‡æ»¤ï¼ˆä¿æŒä¸åŸç‰ˆä¸€è‡´ï¼‰
                condition_on_previous_text=False  # ç¦ç”¨ä¸Šä¸‹æ–‡ä¾èµ–ï¼Œæé«˜é€Ÿåº¦
            )
            
            elapsed_time = time.time() - start_time
            logger.info(f"ğŸ” [è¯Šæ–­] transcribe() è°ƒç”¨å®Œæˆï¼ˆè¿”å›ç”Ÿæˆå™¨ï¼‰ï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")
            
            # è¯Šæ–­ï¼šæ£€æŸ¥è¿”å›ç»“æœ
            logger.info(f"ğŸ” [è¯Šæ–­] info ç±»å‹: {type(info)}")
            logger.info(f"ğŸ” [è¯Šæ–­] segments ç±»å‹: {type(segments)}")
            logger.info(f"ğŸ” [è¯Šæ–­] æ£€æµ‹åˆ°çš„è¯­è¨€: {info.language}")
            logger.info(f"ğŸ” [è¯Šæ–­] è¯­è¨€æ¦‚ç‡: {info.language_probability:.2f}")
            logger.info(f"ğŸ” [è¯Šæ–­] éŸ³é¢‘æ—¶é•¿: {info.duration:.2f}ç§’")
            
            # éå†ç”Ÿæˆå™¨ï¼Œæ”¶é›†æ‰€æœ‰åˆ†æ®µ
            logger.info("ğŸ” [è¯Šæ–­] å¼€å§‹éå† segments ç”Ÿæˆå™¨...")
            segment_start = time.time()
            
            all_text = []
            all_segments = []
            
            for seg in segments:
                all_text.append(seg.text)
                all_segments.append({
                    "id": seg.id,
                    "start": seg.start,
                    "end": seg.end,
                    "text": seg.text.strip()
                })
            
            segment_time = time.time() - segment_start
            logger.info(f"ğŸ” [è¯Šæ–­] segments éå†å®Œæˆï¼Œè€—æ—¶: {segment_time:.2f}ç§’")
            logger.info(f"ğŸ” [è¯Šæ–­] è·å–åˆ° {len(all_segments)} ä¸ªåˆ†æ®µ")
            
            total_time = time.time() - start_time
            logger.info(f"â±ï¸ faster-whisper æ€»è€—æ—¶: {total_time:.2f}ç§’")
            
            # æ„å»ºè¿”å›ç»“æœ
            output = {
                "text": "".join(all_text).strip(),
                "duration": info.duration,
                "language": info.language,
                "segments": all_segments
            }
            
            logger.info(f"âœ… faster-whisper è½¬å†™æˆåŠŸ: æ–‡æœ¬é•¿åº¦={len(output['text'])}")
            return output
            
        except Exception as e:
            logger.error(f"âŒ faster-whisper è½¬å†™å¤±è´¥: {str(e)}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            raise
    
    def _transcribe_with_openai_api(
        self, 
        audio_path: str,
        language: str
    ) -> Dict:
        """
        ä½¿ç”¨ OpenAI Whisper API è¿›è¡Œè½¬å†™
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç ï¼ˆzh, en, ja, koç­‰ï¼‰
        
        Returns:
            {
                "text": "è½¬å†™æ–‡æœ¬",
                "language": "zh",
                "segments": []
            }
        """
        try:
            logger.info(f"è°ƒç”¨ OpenAI Whisper API: {audio_path}, language={language}")
            
            # 1. æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆOpenAI API é™åˆ¶ 25MBï¼‰
            file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
            if file_size_mb > 25:
                raise ValueError(f"éŸ³é¢‘æ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MBï¼ŒOpenAI API é™åˆ¶ä¸º 25MB")
            
            # 2. æ‰“å¼€éŸ³é¢‘æ–‡ä»¶
            with open(audio_path, "rb") as audio_file:
                # 3. è°ƒç”¨ Whisper API
                # API æ–‡æ¡£: https://platform.openai.com/docs/api-reference/audio/createTranscription
                transcript = self.api_client.audio.transcriptions.create(
                    model=self.model_name,
                    file=audio_file,
                    language=language if language != "zh" else "zh",  # ä¸­æ–‡ä½¿ç”¨ "zh"
                    response_format="verbose_json",  # è·å–è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
                    timestamp_granularities=["segment"]  # è·å–åˆ†æ®µçº§åˆ«çš„æ—¶é—´æˆ³
                )
            
            # 4. è§£æç»“æœ
            result = {
                "text": transcript.text,
                "language": transcript.language or language,
                "segments": []
            }
            
            # 5. æå–åˆ†æ®µä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(transcript, 'segments') and transcript.segments:
                result['segments'] = [
                    {
                        'id': seg.id,
                        'start': seg.start,
                        'end': seg.end,
                        'text': seg.text
                    }
                    for seg in transcript.segments
                ]
                logger.info(f"è·å–åˆ° {len(result['segments'])} ä¸ªåˆ†æ®µ")
            
            logger.info(f"OpenAI Whisper API è½¬å†™æˆåŠŸ: æ–‡æœ¬é•¿åº¦={len(result['text'])}")
            return result
            
        except Exception as e:
            logger.error(f"OpenAI Whisper API è½¬å†™å¤±è´¥: {str(e)}")
            raise
    
    def _convert_audio_if_needed(self, audio_path: str) -> str:
        """
        å¦‚æœéœ€è¦ï¼Œå°†éŸ³é¢‘è½¬æ¢ä¸º wav æ ¼å¼
        
        Args:
            audio_path: åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        Returns:
            str: è½¬æ¢åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸éœ€è¦è½¬æ¢ï¼Œè¿”å›åŸè·¯å¾„ï¼‰
        """
        file_ext = Path(audio_path).suffix.lower()
        
        # å¦‚æœå·²ç»æ˜¯ wav æ ¼å¼ï¼Œä¸éœ€è¦è½¬æ¢
        if file_ext == '.wav':
            return audio_path
        
        # å¯¹äº webmã€ogg ç­‰æ ¼å¼ï¼Œè½¬æ¢ä¸º wav ä»¥æé«˜å…¼å®¹æ€§
        # æ³¨æ„ï¼šWhisper æœ¬èº«æ”¯æŒå¤šç§æ ¼å¼ï¼Œä½† soundfile å¯èƒ½ä¸æ”¯æŒæŸäº›æ ¼å¼
        if file_ext in ['.webm', '.ogg', '.m4a']:
            logger.info(f"æ£€æµ‹åˆ° {file_ext} æ ¼å¼ï¼Œè½¬æ¢ä¸º wav æ ¼å¼ä»¥æé«˜å…¼å®¹æ€§")
            
            try:
                # ä½¿ç”¨ ffmpeg è½¬æ¢éŸ³é¢‘æ ¼å¼
                # æ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨
                try:
                    ffmpeg_bin = _resolve_binary('ffmpeg') or 'ffmpeg'
                    subprocess.run([ffmpeg_bin, '-version'], 
                                 capture_output=True, 
                                 check=True, 
                                 timeout=5)
                except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
                    logger.warning("ffmpeg æœªå®‰è£…æˆ–ä¸å¯ç”¨ï¼Œè·³è¿‡æ ¼å¼è½¬æ¢")
                    logger.warning("Whisper åº”è¯¥èƒ½ç›´æ¥å¤„ç†æ­¤æ ¼å¼ï¼Œä½†å¦‚æœå‡ºç°é—®é¢˜è¯·å®‰è£… ffmpeg")
                    return audio_path
                
                # åˆ›å»ºä¸´æ—¶ wav æ–‡ä»¶
                temp_dir = os.path.dirname(audio_path)
                temp_wav_path = os.path.join(
                    temp_dir, 
                    f"{Path(audio_path).stem}_converted.wav"
                )
                
                # ä½¿ç”¨ ffmpeg è½¬æ¢ï¼šè½¬æ¢ä¸º 16kHz å•å£°é“ wavï¼ˆWhisper æ¨èæ ¼å¼ï¼‰
                cmd = [
                    _resolve_binary('ffmpeg') or 'ffmpeg',
                    '-i', audio_path,      # è¾“å…¥æ–‡ä»¶
                    '-ar', '16000',        # é‡‡æ ·ç‡ 16kHzï¼ˆWhisper æ ‡å‡†ï¼‰
                    '-ac', '1',            # å•å£°é“
                    '-y',                   # è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
                    temp_wav_path          # è¾“å‡ºæ–‡ä»¶
                ]
                
                logger.info(f"æ‰§è¡Œè½¬æ¢å‘½ä»¤: {' '.join(cmd)}")
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
                )
                
                if result.returncode != 0:
                    logger.error(f"ffmpeg è½¬æ¢å¤±è´¥: {result.stderr}")
                    logger.warning("è½¬æ¢å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ–‡ä»¶")
                    return audio_path
                
                if not os.path.exists(temp_wav_path):
                    logger.error("è½¬æ¢åçš„æ–‡ä»¶ä¸å­˜åœ¨")
                    return audio_path
                
                logger.info(f"âœ… éŸ³é¢‘æ ¼å¼è½¬æ¢æˆåŠŸ: {temp_wav_path}")
                return temp_wav_path
                
            except subprocess.TimeoutExpired:
                logger.error("ffmpeg è½¬æ¢è¶…æ—¶")
                return audio_path
            except Exception as e:
                logger.error(f"éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")
                logger.warning("è½¬æ¢å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ–‡ä»¶")
                return audio_path
        
        # å…¶ä»–æ ¼å¼ç›´æ¥è¿”å›åŸè·¯å¾„
        return audio_path
    
    def _get_audio_duration(self, audio_path: str) -> float:
        """
        è·å–éŸ³é¢‘æ—¶é•¿
        
        ä¼˜å…ˆä½¿ç”¨ ffprobeï¼ˆæ”¯æŒæ‰€æœ‰æ ¼å¼åŒ…æ‹¬ webmï¼‰ï¼Œ
        å¦‚æœä¸æ”¯æŒåˆ™ä½¿ç”¨ soundfileï¼ˆä»…æ”¯æŒ wav/flac/ogg ç­‰ï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        Returns:
            float: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        file_ext = Path(audio_path).suffix.lower()
        
        # å¯¹äº webmã€m4a ç­‰æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ ffprobeï¼ˆsoundfile ä¸æ”¯æŒï¼‰
        if file_ext in ['.webm', '.m4a', '.mp3', '.aac']:
            return self._get_duration_with_ffprobe(audio_path)
        
        # å¯¹äº wavã€flacã€ogg ç­‰æ ¼å¼ï¼Œä¼˜å…ˆä½¿ç”¨ soundfileï¼ˆæ›´å¿«ï¼‰
        try:
            info = sf.info(audio_path)
            duration = info.duration
            logger.info(f"ä½¿ç”¨ soundfile è·å–éŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’")
            return duration
        except Exception as e:
            logger.warning(f"soundfile è·å–æ—¶é•¿å¤±è´¥: {str(e)}ï¼Œå°è¯•ä½¿ç”¨ ffprobe")
            return self._get_duration_with_ffprobe(audio_path)
    
    def _get_duration_with_ffprobe(self, audio_path: str) -> float:
        """
        ä½¿ç”¨ ffprobe è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆæ”¯æŒæ‰€æœ‰æ ¼å¼ï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        Returns:
            float: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            cmd = [
                _resolve_binary('ffprobe') or 'ffprobe',
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                audio_path
            ]
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0 and result.stdout.strip():
                duration = float(result.stdout.strip())
                logger.info(f"ä½¿ç”¨ ffprobe è·å–éŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’")
                return duration
            else:
                raise ValueError(f"ffprobe è¿”å›ç©ºç»“æœ: {result.stderr}")
        except FileNotFoundError:
            logger.warning("ffprobe æœªå®‰è£…ï¼Œæ— æ³•è·å–å‡†ç¡®æ—¶é•¿")
            # é™çº§åˆ°æ–‡ä»¶å¤§å°ä¼°ç®—
            return self._estimate_duration_by_size(audio_path)
        except Exception as e:
            logger.warning(f"ffprobe è·å–æ—¶é•¿å¤±è´¥: {str(e)}")
            # é™çº§åˆ°æ–‡ä»¶å¤§å°ä¼°ç®—
            return self._estimate_duration_by_size(audio_path)
    
    def _estimate_duration_by_size(self, audio_path: str) -> float:
        """
        æ ¹æ®æ–‡ä»¶å¤§å°ä¼°ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        Returns:
            float: ä¼°ç®—çš„éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
            # webm å‹ç¼©ç‡è¾ƒé«˜ï¼Œ1MB â‰ˆ 120ç§’ï¼ˆå–å†³äºç ç‡ï¼‰
            # è¿™æ˜¯ä¸€ä¸ªç²—ç•¥ä¼°ç®—ï¼Œå®é™…æ—¶é•¿å¯èƒ½å·®å¼‚è¾ƒå¤§
            estimated_duration = file_size_mb * 120
            logger.warning(f"ä½¿ç”¨ä¼°ç®—çš„éŸ³é¢‘æ—¶é•¿: {estimated_duration:.2f}ç§’ï¼ˆä¸å‡†ç¡®ï¼Œå»ºè®®å®‰è£… ffmpegï¼‰")
            return estimated_duration
        except Exception as e:
            logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {str(e)}")
            return 0.0
    
    def transcribe_with_segments(
        self,
        audio_path: str,
        max_segment_duration: int = 180,
        language: str = "zh"
    ) -> Dict:
        """
        è½¬å†™é•¿éŸ³é¢‘å¹¶æ™ºèƒ½åˆ†æ®µ
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            max_segment_duration: å•æ®µæœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤3åˆ†é’Ÿ
            language: è¯­è¨€ä»£ç 
        
        Returns:
            {
                "text": "å®Œæ•´è½¬å†™æ–‡æœ¬",
                "duration": 600,
                "segments": {
                    "segment_count": 3,
                    "total_duration": 600,
                    "segments": [
                        {
                            "index": 0,
                            "start_time": 0.0,
                            "end_time": 180.5,
                            "text": "ç¬¬ä¸€æ®µæ–‡æœ¬...",
                            "duration": 180.5,
                            "word_count": 256
                        },
                        ...
                    ]
                }
            }
        """
        logger.info(f"å¼€å§‹åˆ†æ®µè½¬å†™: {audio_path}")
        
        # 1. å…ˆè¿›è¡Œå®Œæ•´è½¬å†™
        result = self.transcribe(audio_path, language=language, word_timestamps=True)
        
        # 2. å¦‚æœéŸ³é¢‘è¾ƒçŸ­ï¼ˆ<5åˆ†é’Ÿï¼‰ï¼Œä¸éœ€è¦åˆ†æ®µ
        if result['duration'] < 300:
            logger.info("éŸ³é¢‘è¾ƒçŸ­ï¼Œä¸éœ€è¦åˆ†æ®µ")
            return result
        
        # 3. æ™ºèƒ½åˆ†æ®µ
        if result.get('segments'):
            # ä½¿ç”¨ Whisper çš„åŸå§‹åˆ†æ®µè¿›è¡Œæ™ºèƒ½åˆå¹¶
            segmented = self._smart_segment(
                result['segments'],
                result['duration'],
                max_segment_duration
            )
        else:
            # å¦‚æœæ²¡æœ‰åˆ†æ®µä¿¡æ¯ï¼Œç®€å•æŒ‰æ—¶é—´åˆ‡åˆ†
            segmented = self._simple_segment(
                result['text'],
                result['duration'],
                max_segment_duration
            )
        
        result['segments'] = segmented
        
        logger.info(f"åˆ†æ®µå®Œæˆ: å…±{segmented['segment_count']}æ®µ")
        
        return result
    
    def _smart_segment(
        self,
        whisper_segments: List[Dict],
        total_duration: float,
        max_segment_duration: int
    ) -> Dict:
        """
        æ™ºèƒ½åˆ†æ®µï¼šåŸºäº Whisper çš„æ—¶é—´æˆ³å’Œåœé¡¿
        
        ç­–ç•¥ï¼š
        1. æ£€æµ‹é•¿åœé¡¿ï¼ˆ>2ç§’ï¼‰ä½œä¸ºåˆ†æ®µç‚¹
        2. å•æ®µä¸è¶…è¿‡ max_segment_duration
        3. æœ€ç»ˆæ§åˆ¶åœ¨ 3-5 æ®µ
        """
        segments = []
        current_start = 0
        accumulated_text = ""
        accumulated_duration = 0
        
        for i, seg in enumerate(whisper_segments):
            seg_duration = seg['end'] - seg['start']
            
            # æ£€æµ‹æ¡ä»¶1ï¼šé•¿åœé¡¿
            pause_duration = 0
            if i < len(whisper_segments) - 1:
                pause_duration = whisper_segments[i + 1]['start'] - seg['end']
            
            # æ£€æµ‹æ¡ä»¶2ï¼šæ—¶é•¿è¶…é™
            if accumulated_duration + seg_duration > max_segment_duration or pause_duration > 2.0:
                if accumulated_text:
                    segments.append({
                        'index': len(segments),
                        'start_time': current_start,
                        'end_time': seg['end'],
                        'text': accumulated_text.strip(),
                        'duration': accumulated_duration,
                        'word_count': len(accumulated_text)
                    })
                
                # å¼€å§‹æ–°æ®µ
                current_start = seg['end'] if pause_duration > 2.0 else seg['start']
                accumulated_text = "" if pause_duration > 2.0 else seg['text']
                accumulated_duration = 0 if pause_duration > 2.0 else seg_duration
            else:
                accumulated_text += " " + seg['text']
                accumulated_duration += seg_duration
        
        # æœ€åä¸€æ®µ
        if accumulated_text:
            segments.append({
                'index': len(segments),
                'start_time': current_start,
                'end_time': whisper_segments[-1]['end'],
                'text': accumulated_text.strip(),
                'duration': accumulated_duration,
                'word_count': len(accumulated_text)
            })
        
        return {
            'segment_count': len(segments),
            'total_duration': total_duration,
            'segments': segments
        }
    
    def _simple_segment(
        self,
        text: str,
        duration: float,
        max_segment_duration: int
    ) -> Dict:
        """
        ç®€å•åˆ†æ®µï¼šæŒ‰æ—¶é—´å‡åˆ†
        
        å½“æ²¡æœ‰ Whisper æ—¶é—´æˆ³æ—¶ä½¿ç”¨
        """
        segment_count = max(1, int(duration / max_segment_duration) + 1)
        text_length = len(text)
        segment_text_length = text_length // segment_count
        
        segments = []
        for i in range(segment_count):
            start_idx = i * segment_text_length
            end_idx = (i + 1) * segment_text_length if i < segment_count - 1 else text_length
            segment_text = text[start_idx:end_idx]
            
            segments.append({
                'index': i,
                'start_time': i * max_segment_duration,
                'end_time': min((i + 1) * max_segment_duration, duration),
                'text': segment_text,
                'duration': min(max_segment_duration, duration - i * max_segment_duration),
                'word_count': len(segment_text)
            })
        
        return {
            'segment_count': len(segments),
            'total_duration': duration,
            'segments': segments
        }


# å•ä¾‹å®ä¾‹
_whisper_service = None


def get_whisper_service() -> WhisperService:
    """
    è·å– WhisperService å•ä¾‹
    
    ä½¿ç”¨å•ä¾‹æ¨¡å¼é¿å…é‡å¤åˆ›å»º OpenAI å®¢æˆ·ç«¯
    """
    global _whisper_service
    if _whisper_service is None:
        _whisper_service = WhisperService()
    return _whisper_service

